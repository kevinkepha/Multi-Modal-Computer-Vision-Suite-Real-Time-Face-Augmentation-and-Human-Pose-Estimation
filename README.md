
# MultiModal Computer Vision Suite: RealTime Face Augmentation and Human Pose Estimation

A productionready demonstration of **realtime, humancentric computer vision**:
 **Face Augmentation:** fast face detection and pixelaccurate alpha overlays (brand marks or emojis).
 **Pose Estimation:** YOLOv8based multiperson keypoint detection and skeleton rendering.

Built with **Python, OpenCV, Ultralytics YOLOv8, and Gradio**.



## ✨ Highlights
 **MultiTab Web UI (Gradio):** Run both pipelines in the browser (upload or live webcam).
 **Robust Overlay Engine:** Vectorized **alpha blending** (no pixelbypixel loops).
 **RealTime Pose Analytics:** Ultralytics **YOLOv8Pose** on CPU or GPU.
 **Modular Architecture:** Swap face detector or pose model with minimal code changes.



## 🧩 Architecture

```

Gradio UI (Tabs)
├── Face Augmentation
│    ├── OpenCV Haar Cascade (fast face detect)
│    └── Alpha blending overlay (emoji/brand mark)
└── Pose Estimation
└── YOLOv8npose (keypoints + skeleton)

````



## 📦 Setup

```bash
git clone https://github.com/<yourusername>/cvvisionsuite.git
cd cvvisionsuite
python m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install r requirements.txt
````

### Assets

Place your overlays in `assets/`:

```
assets/
├── emoji_laugh.png
├── emoji_sunglasses.png
└── emoji_mindblown.png
```

> Transparent PNGs recommended. If assets are missing, a fallback overlay is autogenerated.



## ▶️ Run

```bash
python app.py
```

* Open the Gradio URL in your browser.
* **Tab 1 (Face Augmentation):** choose overlay, set scale, and stream from webcam.
* **Tab 2 (Pose Estimation):** visualize keypoints & skeletons in real time.

> Tip (Windows/macOS): grant camera permissions if the webcam feed is blank.



## ⚙️ Configuration

* **Overlay Scale:** multiplier relative to detected face width (0.6–1.6 typical).
* **Randomize Each Frame:** toggle for dynamic overlays on successive frames.
* **Max Faces:** upper bound for processed faces per frame (latency control).
* **YOLO Confidence:** tune box/keypoint thresholds for your scene.



## 📈 Performance Notes

* **CPUonly** works for demos; **GPU** (CUDA) recommended for highFPS pose.
* Use `yolov8spose.pt` or `yolov8mpose.pt` for better accuracy (tradeoff: slower).
* Reduce camera resolution for higher FPS on lowend devices.



## 🔒 Privacy

* Processing is **localonly** by default (no frames leave your machine).
* For production, add consent prompts, ondevice logging controls, and PII policies.



## 🔧 Extensibility

* Swap Haar cascade with RetinaFace / MediaPipe Face Detection for robustness.
* Add **Object Detection** tab (YOLOv8) with custom labels/analytics.
* Stream to RTSP/RTMP sinks or embed in a FastAPI service for deployment.



## 📝 License

MIT — free for commercial and personal use. Attribution appreciated.







