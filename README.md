
# MultiModal Computer Vision Suite: RealTime Face Augmentation and Human Pose Estimation

A productionready demonstration of **realtime, humancentric computer vision**:
 **Face Augmentation:** fast face detection and pixelaccurate alpha overlays (brand marks or emojis).
 **Pose Estimation:** YOLOv8based multiperson keypoint detection and skeleton rendering.

Built with **Python, OpenCV, Ultralytics YOLOv8, and Gradio**.



## âœ¨ Highlights
 **MultiTab Web UI (Gradio):** Run both pipelines in the browser (upload or live webcam).
 **Robust Overlay Engine:** Vectorized **alpha blending** (no pixelbypixel loops).
 **RealTime Pose Analytics:** Ultralytics **YOLOv8Pose** on CPU or GPU.
 **Modular Architecture:** Swap face detector or pose model with minimal code changes.



## ğŸ§© Architecture

```

Gradio UI (Tabs)
â”œâ”€â”€ Face Augmentation
â”‚    â”œâ”€â”€ OpenCV Haar Cascade (fast face detect)
â”‚    â””â”€â”€ Alpha blending overlay (emoji/brand mark)
â””â”€â”€ Pose Estimation
â””â”€â”€ YOLOv8npose (keypoints + skeleton)

````



## ğŸ“¦ Setup

```bash
git clone https://github.com/<yourusername>/cvvisionsuite.git
cd cvvisionsuite
python m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install r requirements.txt
````

### Assets

Place your overlays in `assets/`:

```
assets/
â”œâ”€â”€ emoji_laugh.png
â”œâ”€â”€ emoji_sunglasses.png
â””â”€â”€ emoji_mindblown.png
```

> Transparent PNGs recommended. If assets are missing, a fallback overlay is autogenerated.



## â–¶ï¸ Run

```bash
python app.py
```

* Open the Gradio URL in your browser.
* **Tab 1 (Face Augmentation):** choose overlay, set scale, and stream from webcam.
* **Tab 2 (Pose Estimation):** visualize keypoints & skeletons in real time.

> Tip (Windows/macOS): grant camera permissions if the webcam feed is blank.



## âš™ï¸ Configuration

* **Overlay Scale:** multiplier relative to detected face width (0.6â€“1.6 typical).
* **Randomize Each Frame:** toggle for dynamic overlays on successive frames.
* **Max Faces:** upper bound for processed faces per frame (latency control).
* **YOLO Confidence:** tune box/keypoint thresholds for your scene.



## ğŸ“ˆ Performance Notes

* **CPUonly** works for demos; **GPU** (CUDA) recommended for highFPS pose.
* Use `yolov8spose.pt` or `yolov8mpose.pt` for better accuracy (tradeoff: slower).
* Reduce camera resolution for higher FPS on lowend devices.



## ğŸ”’ Privacy

* Processing is **localonly** by default (no frames leave your machine).
* For production, add consent prompts, ondevice logging controls, and PII policies.



## ğŸ”§ Extensibility

* Swap Haar cascade with RetinaFace / MediaPipe Face Detection for robustness.
* Add **Object Detection** tab (YOLOv8) with custom labels/analytics.
* Stream to RTSP/RTMP sinks or embed in a FastAPI service for deployment.



## ğŸ“ License

MIT â€” free for commercial and personal use. Attribution appreciated.







